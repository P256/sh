#######################################################################################
# logstash.yml
#######################################################################################
input {
  # 输入接收数据
  stdin { }
  # 从redis作为来源
  redis { 
      host      => "10.140.45.190"    # redis主机地址
      port      => 6379               # redis端口号
      db        => 8                  # redis数据库编号
      data_type => "channel"          # 使用发布/订阅模式
      key       => "logstash_list_0"  # 发布通道名称
  }
  # 以文件作为来源
  file {
      path => [
          # 这里填写需要监控的文件
          "/var/log/messages",
          "/var/log/dmesg",
          "/var/log/*.log"
      ]
      type => "system"
  }
  # 从jdbc作为来源
  jdbc {
      schedule                =>"0 0-59 0-23 ? * *"
      jdbc_driver_library     => "mysql-connector-java-5.1.39-bin.jar"
      jdbc_driver_class       => "com.mysql.jdbc.Driver"
      jdbc_connection_string  => "jdbc:mysql://192.168.100.240:3306/data"
      jdbc_user               => "sync"
      jdbc_password           => "sync"
      statement               => "SELECT * from user"
      #statement_filepath     => "jdbc.sql"
      jdbc_paging_enabled     => "true"
      jdbc_page_size          => "50000"
  }
  # 系统log作为来源
  syslog {
      port => "514"
  }
  # 还有很多可以支持
}
filter {
  # 定义数据的格式，正则解析日志（根据实际需要对日志日志过滤、收集）
  grok {
      match => {
        "message" => "%{IPV4:clientIP}|%{GREEDYDATA:request}|%{NUMBER:duration}"
      }
  }
  # 根据需要对数据的类型转换
  mutate {
      convert => { "duration" => "integer" }
  }
  # Json
  json {
      source => "message"
      remove_field => ["message"]
  }
  # 地理位置
  geoip {
      source => "message"
  }
  # 时间
  date {
      match => ["logdate", "dd/MMM/yyyy:HH:mm:ss Z"]
  }
  # 还有很多可以支持
}
# 定义输出
output {
  # 输出到控制台
  stdout { }
  # 输出到redis
  redis {
      host => "10.140.45.190"   # redis主机地址
      port => 6379              # redis端口号
      db => 8                   # redis数据库编号
      data_type => "channel"    # 使用发布/订阅模式
      key => "logstash_list_0"  # 发布通道名称
  }
  # 输出到本地文件
  file { 
      path           => "/data/log/logstash/all.log" # 指定写入文件路径
      message_format => "%{host} %{message}"         # 指定写入格式
      flush_interval => 0                            # 指定刷新间隔，0代表实时写入
  }
  # 输出到es
  elasticsearch {
      hosts       => ["localhost:9200"]
      index       => "log-%{+YYYY.MM.dd}"
      document_id   => "%{id}"
      document_type   => "user"
      workers     => 5
      template_overwrite => true
  }
  # 还有很多可以支持
}　
